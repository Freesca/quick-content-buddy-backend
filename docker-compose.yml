version: "3.9"

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped

  web:
    build:
      context: ./backend
    container_name: django
    env_file: .env
    ports:
      - "8000:8000"
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_MODEL: llama3.2
      DJANGO_ALLOWED_HOSTS: localhost,127.0.0.1,.ngrok-free.app
    volumes:
      - ./backend:/app
    command: sh -c "sleep 5 && python manage.py runserver 0.0.0.0:8000"
    restart: unless-stopped

  ngrok:
    image: ngrok/ngrok:latest
    container_name: ngrok
    command: http web:8000
    environment:
      NGROK_AUTHTOKEN: ${NGROK_AUTHTOKEN}
    depends_on:
      - web
    ports:
      - "4040:4040"
    restart: unless-stopped

volumes:
  ollama_models: